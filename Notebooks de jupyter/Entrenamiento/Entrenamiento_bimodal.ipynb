{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "py_file_location = py_file_location = \"Dirección carpeta con archivos.py AdapNet++ bimodal\"\n",
    "sys.path.append(os.path.abspath(py_file_location))\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import importlib\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "from dataset.helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cce993",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clases='Número de clases'\n",
    "max_it='Número de iteraciones'\n",
    "batch_size='Tamño de lote'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b980d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch():\n",
    "    filenames = ['Dirección archivo tfrecords con ambas modalidades y etiquetas']\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    #parser(x,num_clases)\n",
    "    dataset = dataset.map(lambda x: parser(x, num_clases))\n",
    "    dataset = dataset.shuffle(buffer_size=100)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat(100)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator\n",
    "\n",
    "def get_train_data():\n",
    "    iterator = get_train_batch()\n",
    "    dataA, label, dataB = iterator.get_next()\n",
    "    return [dataA, label, dataB], iterator\n",
    "\n",
    "data_list, iterator = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bca8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = importlib.import_module('models.'+'SSMA')\n",
    "model_func = getattr(module,'SSMA')\n",
    "global_step = tf.Variable(0, trainable=False, name='Global_Step')\n",
    "#Decay_steps=Número de iteraciones\n",
    "model = model_func(num_classes=num_clases, learning_rate=0.01, decay_steps=max_it,power=0.001, global_step=global_step)\n",
    "images_pl = tf.placeholder(tf.float32, [None, 384, 768, 3])\n",
    "images_pl1 = tf.placeholder(tf.float32, [None, 384, 768, 3])\n",
    "labels_pl = tf.placeholder(tf.float32, [None, 384, 768, num_clases])\n",
    "model.build_graph(images_pl, images_pl1, labels_pl)\n",
    "model.create_optimizer()\n",
    "config1 = tf.ConfigProto()\n",
    "config1.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config1)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "step = 0\n",
    "total_loss = 0.0\n",
    "t0 = None\n",
    "path1='Dirección checkpoint AdapNet++ unimodal'\n",
    "path2='Dirección checkpoint AdapNet++ bimodal'\n",
    "      \n",
    "import_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "\n",
    "initialize_variables={}\n",
    "#Listas con las capas de los checkpoints que se van a cargar\n",
    "inspect_list1 = tf.train.list_variables(path1)\n",
    "inspect_list2 = tf.train.list_variables(path2)\n",
    "names=[]\n",
    "names2=[]\n",
    "names_no_cargar=[]\n",
    "trainable_collection=tf.get_collection_ref(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "\n",
    "\n",
    "for item in inspect_list1:\n",
    "    names.append(item[0])\n",
    "for item in inspect_list2:\n",
    "    names2.append(item[0])\n",
    "\n",
    "    #CARGAR ENCODERS \n",
    "for var in import_variables:\n",
    "    if 'depth' in var.name:\n",
    "        temp1=var.name.replace('depth'+'/', '')\n",
    "        temp=temp1.split(':')\n",
    "        if temp[0] in names:\n",
    "            initialize_variables[temp[0]]=var\n",
    "            \n",
    "saver=tf.train.Saver(initialize_variables)         \n",
    "saver.restore(sess,path1)\n",
    "initialize_variables={}\n",
    "\n",
    "for var in import_variables:\n",
    "    if 'rgb' in var.name:\n",
    "        temp1=var.name.replace('rgb'+'/', '')\n",
    "        temp=temp1.split(':')\n",
    "        if temp[0] in names:\n",
    "            initialize_variables[temp[0]]=var\n",
    "            \n",
    "saver=tf.train.Saver(initialize_variables)    \n",
    "saver.restore(sess,path1)\n",
    "   #CARGAR DECODER Y SSMA\n",
    "initialize_variables={}\n",
    "SSMA=['conv511','conv512','conv513','conv514','conv515','conv518','conv519','conv552','conv553']\n",
    "DECODER=['conv41','conv16','conv89','conv96','conv88','conv95']\n",
    "\n",
    "for var in import_variables:\n",
    "    temp1=var.name.split('/')[0]\n",
    "    if temp1 in SSMA or temp1 in DECODER:\n",
    "        temp=var.name.split(':')\n",
    "        if temp[0] in names2:\n",
    "            initialize_variables[temp[0]]=var\n",
    "saver=tf.train.Saver(initialize_variables) \n",
    "saver.restore(sess,path2)\n",
    "#Número de checkpoints que se quieren guardar\n",
    "saver = tf.train.Saver(max_to_keep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perdidas=[]\n",
    "while 1:\n",
    "        try: \n",
    "            img, label, img1 = sess.run([data_list[0], data_list[1], data_list[2]]) \n",
    "            feed_dict = {images_pl: img, labels_pl: label, images_pl1: img1}\n",
    "            loss_batch, _ = sess.run([model.loss, model.train_op],feed_dict=feed_dict)\n",
    "\n",
    "            total_loss += loss_batch\n",
    "            #Se guarda un checkpoint cada 100 iteraciones\n",
    "            if (step + 1) % 100 == 0:\n",
    "                saver.save(sess, os.path.join('Dirección en la que se guarda el checkpoint', 'nombre del checkpoint'), step)\n",
    "\n",
    "            if (step + 1) % 10 == 0:\n",
    "                #Cada 10 iteraciones se muestra la pérdida\n",
    "                left_hours = 0\n",
    "\n",
    "                if t0 is not None:\n",
    "                    delta_t = (datetime.datetime.now() - t0).seconds\n",
    "                     #left time=(numero_iteraciones-step)/10*delta_t\n",
    "                    left_time = (2000 - step) / 10 * delta_t\n",
    "                    left_hours = left_time/3600.0\n",
    "\n",
    "                t0 = datetime.datetime.now()\n",
    "                #media de las 10 iteraciones\n",
    "                total_loss /= 10\n",
    "                perdidas.append(total_loss)\n",
    "                print ('%s %s] Step %s, lr = %f ' \\\n",
    "                  % (str(datetime.datetime.now()), str(os.getpid()), step,\n",
    "                     model.lr.eval(session=sess)))\n",
    "                print ('\\t loss = %.4f' % (total_loss))\n",
    "                print ('\\t estimated time left: %.1f hours. %d/%d' % (left_hours, step,2000))\n",
    "                print ('\\t', 'SSMA')\n",
    "                total_loss = 0.0\n",
    "\n",
    "            step += 1\n",
    "            #if step>número iteraciones\n",
    "            if step > 2000:\n",
    "                saver.save(sess, os.path.join('Dirección en la que se guarda el checkpoint', 'nombre del checkpoint'), step-1)\n",
    "                print ('training_completed')\n",
    "                break\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print ('Epochs in dataset repeat < max_iteration')\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
