{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "py_file_location = py_file_location = \"Introducir dirección archivos.py AdapNet++\"\n",
    "sys.path.append(os.path.abspath(py_file_location))\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import importlib\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "from dataset.helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clases='Número de clases'\n",
    "max_it='Número de iteraciones'\n",
    "batch_size='Tamño de lote'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch():\n",
    "    filenames = ['Dirección archivo tfrecords con imágenes y sus etiquetas']\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(lambda x: parser(x, num_clases))\n",
    "    dataset = dataset.shuffle(buffer_size=100)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat(100)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator\n",
    "\n",
    "def get_train_data():\n",
    "    iterator = get_train_batch()\n",
    "    dataA, label = iterator.get_next()\n",
    "    return [dataA, label], iterator\n",
    "\n",
    "data_list, iterator = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661be7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = importlib.import_module('models.'+'AdapNet_pp')\n",
    "model_func = getattr(module, 'AdapNet_pp')\n",
    "resnet_name = 'resnet_v2_50'\n",
    "global_step = tf.Variable(0, trainable=False, name='Global_Step')\n",
    "\n",
    "with tf.variable_scope(resnet_name):\n",
    "    model = model_func(num_classes=num_clases, learning_rate=0.01,decay_steps=max_it, power=0.01 ,global_step=global_step)\n",
    "    images_pl = tf.placeholder(tf.float32, [None, 384, 768, 3])\n",
    "    labels_pl = tf.placeholder(tf.float32, [None, 384, 768, num_clases])\n",
    "    model.build_graph(images_pl, labels_pl)\n",
    "    model.create_optimizer()\n",
    " \n",
    "config1 = tf.ConfigProto()\n",
    "config1.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config1)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "step = 0\n",
    "total_loss = 0.0\n",
    "t0 = None\n",
    "import_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "\n",
    "path='Dirección checkpoint'\n",
    "\n",
    "inspect_list = tf.train.list_variables(path)\n",
    "names=[]\n",
    "\n",
    "for item in inspect_list:\n",
    "  if  'conv78/' in item[0] or 'conv5/' in item[0] or 'conv911/' in item[0] or 'conv912/' in item[0]:\n",
    "    print('No entra en names: ', item[0])\n",
    "  else:\n",
    "    names.append(item[0])\n",
    "\n",
    "initialize_variables={}\n",
    "for var in import_variables:\n",
    "    temp=var.name.split(':')\n",
    "    if temp[0] in names:\n",
    "        initialize_variables[temp[0]]=var\n",
    "\n",
    "trainable_collection = tf.get_collection_ref(tf.GraphKeys.TRAINABLE_VARIABLES) \n",
    "for i in range(204):\n",
    "  trainable_collection.pop(0)\n",
    "\n",
    "saver=tf.train.Saver(initialize_variables)\n",
    "saver.restore(sess,path)\n",
    "#Número de checkpoints a guardar\n",
    "saver = tf.train.Saver(max_to_keep=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca995f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista con el valor de las pérdidas\n",
    "perdidas=[]\n",
    "while 1:\n",
    "        try: \n",
    "            img, label = sess.run([data_list[0], data_list[1]]) \n",
    "            feed_dict = {images_pl: img, labels_pl: label}\n",
    "            loss_batch, _ = sess.run([model.loss, model.train_op],feed_dict=feed_dict)\n",
    "\n",
    "            total_loss += loss_batch\n",
    "            #Se guarda un checkpoint cada 10 iteraciones\n",
    "            if (step + 1) % 10 == 0:\n",
    "                saver.save(sess, os.path.join('Dirección en la que se guarda el checkpoint', 'nombre del checkpoint'), step)\n",
    "\n",
    "            if (step + 1) % 10 == 0:\n",
    "                left_hours = 0\n",
    "\n",
    "                if t0 is not None:\n",
    "                    delta_t = (datetime.datetime.now() - t0).seconds\n",
    "                    left_time = (max_it - step) / 10 * delta_t\n",
    "                    left_hours = left_time/3600.0\n",
    "\n",
    "                t0 = datetime.datetime.now()\n",
    "                total_loss /= 10\n",
    "              \n",
    "                perdidas.append(total_loss)\n",
    "                print ('%s %s] Step %s, lr = %f ' \\\n",
    "                  % (str(datetime.datetime.now()), str(os.getpid()), step,\n",
    "                     model.lr.eval(session=sess)))\n",
    "                print ('\\t loss = %.4f' % (total_loss))\n",
    "                print ('\\t estimated time left: %.1f hours. %d/%d' % (left_hours, step,max_it))\n",
    "                print ('\\t', 'SSMA')\n",
    "                total_loss = 0.0\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            if step > max_it:\n",
    "                saver.save(sess, os.path.join('Dirección en la que se guarda el checkpoint', 'nombre del checkpoint'), step-1)\n",
    "                print ('training_completed')\n",
    "                break\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print ('Epochs in dataset repeat < max_iteration')\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
