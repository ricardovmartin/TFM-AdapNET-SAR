{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed44464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "py_file_location = \"Dirección archivos.py AdapNet++\"\n",
    "sys.path.append(os.path.abspath(py_file_location))\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import importlib\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "from dataset.helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96983052",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clases='Número de clases'\n",
    "max_it='Número de iteraciones'\n",
    "batch_size='Tamño de lote'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36489efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch():\n",
    "    filenames = ['Dirección tfrecords imágenes y etiquetas']\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(lambda x: parser(x, num_clases))\n",
    "    dataset = dataset.shuffle(buffer_size=100)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat(100)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator\n",
    "\n",
    "def get_train_data():\n",
    "    iterator = get_train_batch()\n",
    "    dataA, label, dataB = iterator.get_next()\n",
    "    return [dataA, label, dataB], iterator\n",
    "\n",
    "data_list, iterator = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7790444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = importlib.import_module('models.'+'SSMA')\n",
    "model_func = getattr(module,'SSMA')\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='Global_Step')\n",
    "\n",
    "model = model_func(num_classes=num_clases, learning_rate=0.001, decay_steps=max_it,power=0.0001, global_step=global_step)\n",
    "images_pl = tf.placeholder(tf.float32, [None, 384, 768, 3])\n",
    "images_pl1 = tf.placeholder(tf.float32, [None, 384, 768, 3])\n",
    "labels_pl = tf.placeholder(tf.float32, [None, 384, 768, num_clases])\n",
    "model.build_graph(images_pl, images_pl1, labels_pl)\n",
    "model.create_optimizer()\n",
    "config1 = tf.ConfigProto()\n",
    "config1.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config1)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "step = 'Iteración a partir de la que se inicia el fine-tuning'\n",
    "total_loss = 0.0\n",
    "t0 = None\n",
    "path='Dirección checkpoint'\n",
    "import_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "\n",
    "initialize_variables={}\n",
    "trainable_collection=tf.get_collection_ref(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "#Lista con las capas entrenables\n",
    "names=[]\n",
    "for item in trainable_collection:\n",
    "    temp=item.name.split(':')\n",
    "    names.append(temp[0])\n",
    "\n",
    "for var in import_variables:\n",
    "  temp=var.name.split(':')\n",
    "  if temp[0] not in names:\n",
    "    trainable_collection.append(var)\n",
    "    \n",
    "    \n",
    "saver=tf.train.Saver(import_variables)\n",
    "saver.restore(sess,path)\n",
    "#Número de checkpoints a guardar\n",
    "saver = tf.train.Saver(max_to_keep=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "perdidas=[]\n",
    "while 1:\n",
    "      try: \n",
    "          img, label, img1 = sess.run([data_list[0], data_list[1], data_list[2]]) \n",
    "          feed_dict = {images_pl: img, labels_pl: label, images_pl1: img1}\n",
    "          loss_batch, _ = sess.run([model.loss, model.train_op],feed_dict=feed_dict)\n",
    "          total_loss += loss_batch\n",
    "        #Se guarda un checkpoint cada 10 iteraciones\n",
    "          if (step + 1) % 10 == 0:\n",
    "              saver.save(sess, os.path.join('Dirección para guardar checkpoint', 'nombre del checkpoint'), step)\n",
    "\n",
    "          if (step + 1) % 10 == 0:\n",
    "              left_hours = 0\n",
    "\n",
    "              if t0 is not None:\n",
    "                  delta_t = (datetime.datetime.now() - t0).seconds\n",
    "                    #left_time=(num_iteraciones-step)/10-delta_t\n",
    "                  left_time = (max_it - step) / 10 * delta_t\n",
    "                  left_hours = left_time/3600.0\n",
    "\n",
    "              t0 = datetime.datetime.now()\n",
    "            #Media de las pérdidas a lo largo de las 10 iteraciones\n",
    "              total_loss /= 10\n",
    "              perdidas.append(total_loss)\n",
    "              print ('%s %s] Step %s, lr = %f ' \\\n",
    "                % (str(datetime.datetime.now()), str(os.getpid()), step,\n",
    "                    model.lr.eval(session=sess)))\n",
    "              print ('\\t loss = %.4f' % (total_loss))\n",
    "              print ('\\t estimated time left: %.1f hours. %d/%d' % (left_hours, step,max_it))\n",
    "              print ('\\t', 'SSMA')\n",
    "              total_loss = 0.0\n",
    "\n",
    "          step += 1\n",
    "\n",
    "          if step > max_it:\n",
    "              saver.save(sess, os.path.join('Dirección para guardar checkpoint', 'nombre del checkpoint'), step-1)\n",
    "              print ('training_completed')\n",
    "              break\n",
    "\n",
    "      except tf.errors.OutOfRangeError:\n",
    "          print ('Epochs in dataset repeat < max_iteration')\n",
    "          break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
